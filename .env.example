OPENAI_API_KEY=
MODEL_NAME="gpt-realtime"

# Local vision model (only used with --local-vision CLI flag)
# By default, vision is handled by gpt-realtime when the camera tool is used
LOCAL_VISION_MODEL=HuggingFaceTB/SmolVLM2-2.2B-Instruct

# Cache for local VLM (only used with --local-vision CLI flag)
HF_HOME=./cache

# Hugging Face token for accessing datasets/models
HF_TOKEN=

# To select a specific profile with custom instructions and tools, to be placed in profiles/<myprofile>/__init__.py
REACHY_MINI_CUSTOM_PROFILE="example"

# Idle signal configuration (cost optimization)
# When enabled, robot will perform autonomous actions (dance, look around) when idle
# Set to false to completely disable idle animations (reduces API costs by 85-90%)
ENABLE_IDLE_SIGNALS=true

# Timeout in seconds before sending idle signal (default: 300 = 5 minutes)
# Note: Actual timeout will vary by ±25% for more natural behavior
# Example: 300s → random range of 225-375 seconds (3.75-6.25 minutes)
# Lower values = more active personality but higher costs
# Higher values = less frequent idle animations but lower costs
IDLE_SIGNAL_TIMEOUT=300